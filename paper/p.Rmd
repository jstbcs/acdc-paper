---
title             : "Attentional Control Data Collection: A Resource for Efficient Data Reuse"
shorttitle        : "Attentional Control Data Collection"

author: 
  - name          : "Julia M. Haaf"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "Nieuwe Achtergracht 129B, 1018 WT Amsterdam, The Netherlands."
    email         : "j.m.haaf@uva.nl"
    role:         # Contributorship roles (e.g., CRediT, https://casrai.org/credit/)
      - "Conceptualization"
      - "Writing - Original Draft Preparation"
      - "Writing - Review & Editing"
  - name          : "Madlen Hoffstadt"
    affiliation   : "1"
    role:
      - "Conceptualization"
      - "Writing - Original Draft Preparation"
      - "Writing - Review & Editing"
  - name          : "Sven Lesche"
    affiliation   : "2"
    role:
      - "Conceptualization"
      - "Writing - Original Draft Preparation"
      - "Writing - Review & Editing"

affiliation:
  - id            : "1"
    institution   : "University of Amsterdam"
  - id            : "2"
    institution   : "University of Heidelberg"

authornote: |
  We are indebted to Arte Bischop for her thesis work on the initial SQL data base.
  
  This work was supported in part by a Veni grant from the NWO (VI.Veni.201G.019) and a talent grant by Amsterdam Brain & Cognition (ABC.T09.0921) to J.M.H.

abstract: |
  One or two sentences providing a **basic introduction** to the field,  comprehensible to a scientist in any discipline.
  
  Two to three sentences of **more detailed background**, comprehensible  to scientists in related disciplines.
  
  One sentence clearly stating the **general problem** being addressed by  this particular study.
  
  One sentence summarizing the main result (with the words "**here we show**" or their equivalent).
  
  Two or three sentences explaining what the **main result** reveals in direct comparison to what was thought to be the case previously, or how the  main result adds to previous knowledge.
  
  One or two sentences to put the results into a more **general context**.
  
  Two or three sentences to provide a **broader perspective**, readily comprehensible to a scientist in any discipline.
  
  <!-- https://tinyurl.com/ybremelq -->
  
keywords          : "Open Data, Attentional Control, SQL"
wordcount         : "X"
note              : "Version 1, October 2023"

floatsintext      : yes
linenumbers       : yes
draft             : no
mask              : no

figurelist        : no
tablelist         : no
footnotelist      : no
annotate_references: yes
urlcolor: blue

header-includes:
  - \usepackage{mathrsfs}
  - \usepackage[makeroom]{cancel}
  - \usepackage{pcl}
  - \usepackage{setspace}\doublespacing
  - \usepackage{marginnote}
  - \newcommand{\readme}[1]{\emph{\marginnote{\color{red}Julia} (#1)}}
  - \usepackage{pifont}
  - \usepackage{hyperref}
  - \usepackage{colortbl}
  - \hypersetup{colorlinks=true,urlcolor=blue,citecolor=black,linkcolor=black}
  
classoption       : "man"
output            : papaja::apa6_pdf
csl               : apa6.csl
bibliography: [references.bib, db.bib, lab.bib]
---

```{r setup, include = FALSE}
library("papaja")
library("acdcquery")
library("BayesFactor")
library("MCMCpack")
library("splithalf")
library("tidyverse")
library("ggplot2")
library("dplyr")

r_refs("r-references.bib")
```

```{r analysis-preferences}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
```

Making data openly available has been a central demand by reformers since the start of the reproducibility crisis in psychology [REFS]. Fortunately, this demand has lead to a considerable increase in data availability. While only about 25% of data were shared after request in 2006 [@Wicherts:etal:2006], publicly sharing data upon publication is now more and more the norm. This cultural shift is also increasingly institutionalized. Universities and funding agencies prioritize open data, and some journals even mandate the publication of data with every published article [@Sloman:2015]. In addition, technology like the Open Science Framework (OSF) and other data sharing facilities enable an easy process for researchers, further reducing barriers to share data.

Data sharing serves two goals: 1. To make the scientific process more transparent and enable error and fraud detection, and 2. to make the scientific process more efficient by allowing data reuse for different research projects. Current data sharing efforts, however, seemingly focus overwhelmingly on the first goal [REF Cruewell et al, 2023]. Whenever researchers complying with common data sharing procedures publish an article, they share the corresponding data on the OSF, ideally in a format that allows to redo the exact analyses reported in the article. The OSF repository is linked in the article, and readers may access the data through this link and check whether analysis code and shared data correspond to the results section in the article. This setup, while appropriate for the first goal of data sharing, ignores the second goal of data reuse.

To enable data reuse, data sharing needs to be approached differently. For example, consider a researcher (like the first author of the current paper) might me interested in the Stroop task [@Stroop:1935]. The Stroop task is popular in cognitive psychology [@MacLeod:1991], so we may assume that many studies include this or similar tasks in their studies. Instead of running yet another Stroop experiment, the researcher decides to use existing data to explore their research question before designing a more targeted study. First, the researcher needs to be able to find open Stroop task data. Currently, they could either search for papers on the topic and check whether open data are provided, or search directly via OSF or other data sharing servers. However, neither of these options is very promising as the vast majority of articles in the literature does not provide raw data and data sharing servers are not equipped with sufficient search options. Second, data sets need to be accessed easily and in a general, understandable format ready for reuse. There are data sharing formats that provide this structure [REF], but they are rarely used. Additionally, data are usually shared on the level necessary for the original analysis. In case of the Stroop task, shared data might provide the Stroop effect per participant, but for this new analysis the researcher needs trial-level data. So again, there is yet another barrier for data reuse.

We think it is necessary to provide a data sharing solution that solves the current problems and enables easy and efficient data reuse. Here, we propose to gather open data sets from a specific research area in an SQL data base. This process requires little to no work in addition to current data sharing policies from the authors of original papers, some work from the lab(s) setting up the data base, and little to no work from the researchers who wish to reuse open data. We describe the process and structure we used to set up a data base of attentional control tasks called the Attentional Control Data Collection (ACDC). The data base includes XXX data sets from XXX publications from tasks like the Stroop, Simon, and flanker tasks. Subsequently, we show how the data can be explored using a Shiny app and accessed using an R-package. In an example analysis, we assess the reliability of the included tasks. This section highlights how an open data base like ACDC can aid meta-analytic efforts as well as methodological innovation.

To provide a little history of the project, the Attentional Control Data Collection was inspired by a collection of open data sets from attentional control tasks by the Perception and Cognition Lab led by J. Rouder ([url](https://github.com/PerceptionCognitionLab/data0)). Colleagues provided the first author and Rouder with data sets for their statistical work [@Haaf:Rouder:2017; @Rouder:etal:2023]. To ensure that data sets were accessible, we gathered them in a github repository. However, there was little structure to the collection, and github repositories are neither stable entities nor are they designed as data storage. Here, we describe how a structured data collection can be achieved and which benefits it provides.

# SQLight Database

One of the most standard ways in computer science for storing data is using a Structured query language (SQL) data base. SQL allows to create, access and manipulate a structured data storage. SQL data bases consist of data tables and relations between these tables. There are many flavors of SQL data bases. Here, we decided to use an SQLight data base, a lightweight solution that allows us to store the entire data base in a single file of moderate size that can be downloaded by researchers for data reuse. In this section we describe the structure of the data base and the data currently included. Researchers who simply want to use ACDC may safely skip this section.

## Database Structure

SQL databases are composed of several data tables consisting of rows and columns. Each row in a data table has a primary key (essentially a row ID) which uniquely identifies it. To connect one table to another table in the database, tables may contain foreign keys which reference a unique row in another data table. In contrast to primary keys, these foreign keys can have duplicate values in the data table, as long as they are unique in their primary table. For instance, a study table may store information about all studies in a database where each row corresponds to a single study. Here the primary key is the study_id. We can ensure that our database links each study to the publication it was published in by adding a foreign key called publication_id. This foreign key references the unique identifier of the respective publication in a publication table. Figure \@ref(fig:figure1) illustrates the relationship between study table and publication table. While publication_id links to a single row in the publication table, it can occur several times in the study_table as there can be several studies per publication.

(ref:caption-figure1) Illustrative example of using foreign and primary keys in a SQL database. 

```{r figure1, fig.cap = "(ref:caption-figure1)", out.width=350, fig.align='center'}
knitr::include_graphics("images/illustrate_SQL_keys.png")
```

ACDC is adapted to the logic of publications consisting of one or multiple studies which in turn include one or several data sets. The whole structure of ACDC is shown in Figure \@ref(fig:figure2). A *publication table* and a *study table* contain specific information about each publication and study, respectively. Each data set within a study stores trial-level information about a single attentional control task within a certain study. If a between-subject manipulation exists, our data base contains a separate data set for each group and each task. For instance, a study in which two groups (younger and older adults) who completed a Simon and a Stroop task would consist of four data sets (i.e., younger-Stroop, younger-Simon, older-Stroop, older-Simon) in the ACDC data base. 

A *data set table* stores information about each data set, such as sample size, the number of within-participant manipulations, and whether a fixation cross was used. The *observation table* hold the trial-level attentional control task data (including response time and accuracy). The task type of each data set (i.e., Stroop, Simon, Flanker, negative priming, or other) and a description of which stimuli were presented in the task are documented in the *task table*. 

Note that since the congruency of stimuli, i.e., whether response and stimulus attributes are compatible or incompatible, is part of every attentional control task, it is not considered a separate within-participant manipulation in this database but is per default included in the observation table. Any additional within-participant manipulations are coded in the within ID column of the observation table. Further information about each condition of each data set (such as the percentage of congruent trials, mean response time, and mean accuracy) are recorded in the *within table*. 

(ref:caption-figure2) Structure of the ACDC database. Primary keys are indicated by the key symbol. References between data tables are illustrated through lines connecting columns across data tables. This overview includes the data type of each column: integers (int), numbers with decimal places (float), characters (varchar) and logical true/false values (Booleans).

```{r figure2, fig.cap = "(ref:caption-figure2)"}
knitr::include_graphics("images/db_structure.png")
```

## Included Data

```{r data-overview, echo = F, eval = T, cache = T, message=F, warning=F}
library(acdcquery)

dbfile <- tempfile(fileext=".sqlite") # not created yet, just a string
download.file("https://github.com/jstbcs/acdc-database/raw/main/acdc.db", dbfile)

conn <- connect_to_db(dbfile)

arguments <-  list()
arguments <- add_argument(
 list = arguments,
 conn = conn,
 variable = "study_id",
 operator = "greater",
 values = c(-1)
)

query_results <- query_db(
 conn = conn,
 arguments = arguments,
 target_vars = c("default", "publication_id", "publication_code")
)

# head(query_results)
K <- length(unique(query_results$dataset_id))
I <- length(unique(query_results$publication_id))
n_participants <- length(unique(query_results$subject))
n_obs <- nrow(query_results)
```

Up to the date of submission of the manuscript, `r K` data sets from `r I` publications are included in the database. The full list of data sets and references is provided in the Appendix. The current database includes data sets from studies with an experimental as well as a correlational focus. The data contain $10^ `r round(log10(n_obs))`$ observations collected from `r n_participants` participants.

We did not conduct a systematic search for data sets nor attempted to distribute a wider call for open data. Instead, we included the data sets that were already made available to the lab for previous projects, and added data sets from collaborators bit by bit. This approach was chosen to make the project feasible, and to first set up a working data base before large quantities of data are added.

## Contribute

\readme{TODO: Add a brief description on how researcher can add their own data.}

# Accessing the Database

One advantage of SQLite databases is that they are simply a file that can be downloaded and locally accesses by anyone. Our database is provided in a github repository.^[The newest version can be accessed via [https://github.com/jstbcs/acdc-database/blob/main/acdc.db](https://github.com/jstbcs/acdc-database/blob/main/acdc.db), the version at the time of submission can be found [here](https://github.com/jstbcs/acdc-database/blob/main/acdc.db). \readme{TODO: REPLACE WITH CURRENT COMMIT.}] To access the database, researchers can download the file `acdc.db`, and use the SQLite tool of their choice. In addition, we build `R`-based tools to inspect, access, and select data from ACDC. We introduce these tools, a shiny app and an `R` package, subsequently.

## Shiny App

The easiest way to inspect the data is using our shiny app provided [here](LINKTOSHINYAPP). The app allows to inspect all data sets or select data sets with certain specification using the filter box on the left. For example, if a researcher is interested in the flanker task, they may select all flanker data sets for closer inspection. After selection, researchers can choose between an overview of the included data sets, some descriptive statistics, and descriptive plots (see Figure XXX). If they want to further analyze the data, they can download the data via the "get the data tab", either directly as `csv` file or using the provided `R`-code.

\readme{TODO: Add screenshot from the shiny app as figure.}

Note that all descriptive statistics in the data base are aggregated across congruency conditions. This was a deliberate choice when designing the shiny app. By withholding information about the effect of interest, researches can inspect and select the data based on varying characteristics of the data set (including distributional properties), but remain unbiased as to the most relevant outcome variable. We hope that researchers can then formulate (and perhaps preregister) hypotheses about their reanalysis without much hindsight bias.

\readme{TODO: Add example descriptive plots.}

## R-Package

\readme{SVEN: Add an overview or the R package.}

```{r package-install, echo = T, eval = F}
install.packages("acdcquery") # install package

library(acdcquery) # load package
```

## Queries and Output

\readme{SVEN: Show and explain an example query with several arguments, selection of the target table, etc.}

# Reliability of ACDC Tasks

```{r data-loading, cache = T, warning=FALSE}
# head(query_results)
get_n_unique <- function(x) length(unique(x))
datID <- get_n_unique(query_results$dataset_id)
n_obs <- table(query_results$dataset_id)
pubCode <- with(query_results, tapply(publication_code, dataset_id, first))
n_participants <- with(query_results, tapply(subject, dataset_id, get_n_unique))


dat_tab <- data_frame(pubCode, n_participants, n_obs)
dat <- query_results
```

```{r source-helper}
source("../share/helper_functions.R")
```

```{r hierarchical-modeling, cache = T, eval = T}
res <- list()
ids.sel <- 1:length(unique(dat$dataset_id))

for(i in ids.sel){
  dat_sub <- subset(dat, dataset_id == i)
  dat_sub <- subset(dat_sub, accuracy == 1)
  dat_sub <- subset(dat_sub, rt > .2)
  dat_sub <- subset(dat_sub, rt < 2.5)
  dat_sub <- subset(dat_sub, congruency %in% 1:2)
  issue <- issue.sub(dat_sub)
  dat_sub <- subset(dat_sub, !(subject %in% issue))
  
  res[[paste0("dataset_", i)]] <- genModOneTask(dat_sub)
  # print(i)
}
```

```{r get_stn}
stn <- matrix(ncol = 3, nrow = length(ids.sel))
for(i in ids.sel){
  tmp <- res[[i]]
  stn[i, 1] <- mean(tmp$s2Theta / tmp$s2)
  stn[i, 2] <- get.I(subset(dat, dataset_id == i))
  stn[i, 3] <- get.K(subset(dat, dataset_id == i))
}
```


To illustrate how ACDC can be used for reanalysis, and to further assess the reliability of attentional control tasks included, we provide an example data analysis. The reliability of attentional control tasks auch as the Stroop task has been critically discussed in recent literature [@Hedge:etal:2018; @Rouder:Haaf:2019a; @Rouder:etal:2023; @ReyMermet:etal:2018; @Draheim:etal:2019]. Here, we rely on methodological development by Rouder and colleagues @[Rouder:Haaf:2019a; @Rouder:etal:2023] to survey the reliability of data sets in ACDC. This analysis can be understood as an extension of to...

(ref:caption-line-plot) Signal-to-noise ratio and reliability. A. Signal-to-noise ratio $\gamma$ for all data sets ordered from smallest to largest. B. Reliability as a function of number of trials for all data sets in ACDC. The lines represent different signal-to-noise ratios. For a fixed $\gamma$, the relationship between the number of trials per condition and the reliability is deterministic.

```{r line-plot, fig.asp = 1, fig.width=4.5, fig.align='center', fig.cap = "(ref:caption-line-plot)"}
layout(matrix(c(0, 1, 1, 0, rep(2, 4)), ncol = 4, byrow = T)
       , heights = c(.4,.6))

myCols <- RColorBrewer::brewer.pal(8, "Dark2")
par(mgp = c(2.3, .7, 0), mar = c(3.5,4,2,1), cex.lab = 1.3)

plot(ids.sel, sort(sqrt(stn[, 1]))
     , col = myCols[1]
     , pch = 19, cex = 1.3
     , ylab = expression("Signal-to-noise" ~ gamma)
     , xlab = "Data set"
     , axes = F
     , xlim = c(0, length(ids.sel) + 7)
     , ylim = c(0, .4)
     )
mtext("A.", adj = .5)
axis(1, c(1, length(ids.sel)), cex.axis = 1.3)
axis(2, seq(0, .4, .1), cex.axis = 1.3, las=1)
abline(h = 1/15, col = adjustcolor(1, .8))
text(length(ids.sel) + 4, 1/15 + .02, "1/15", cex = 1.2)
abline(h = 1/9, col = adjustcolor(1, .6))
text(length(ids.sel) + 4, 1/9 + .02, "1/9", cex = 1.2)
abline(h = 1/5, col = adjustcolor(1, .4))
text(length(ids.sel) + 4, 1/5 + .02, "1/5", cex = 1.2)
abline(h = 1/3, col = adjustcolor(1, .2))
text(length(ids.sel) + 4, 1/3 + .02, "1/3", cex = 1.2)

dots = list("l" = stn[, 3], "g" = sqrt(stn[, 1]))
makeRelCoefFig(dots = dots, Var = FALSE)
mtext("B.", adj = .5, line = -1)
```

# Discussion

\newpage

# Appendix

\readme{INSERT TABLE WITH ALL DATASETS AND PUBLICATION REFERENCE HERE.}

\newpage

# References

::: {#refs custom-style="Bibliography"}
:::
